\chapter{PENDAHULUAN}
\label{chap:pendahuluan}

Penelitian ini didorong oleh kemajuan pesat dalam teknologi komputasi
modern, yang menuntut adanya teknik-teknik yang lebih canggih untuk
manajemen \textit{cache} objek. Dalam beberapa tahun terakhir,
\textit{machine learning} telah menjadi topik yang sangat populer
dalam riset ilmu komputer. Berbagai studi telah dilakukan untuk
memahami sejauh mana kapabilitas \textit{machine learning} dapat
diterapkan dalam bidang \textit{caching}. Penelitian ini secara
spesifik menyelidiki bagaimana \textit{machine learning} dapat
diimplementasikan dalam sistem \textit{cache} untuk meningkatkan
efisiensi algoritma populer seperti CLOCK.

\section{Latar Belakang}
\label{sec:latar_belakang}

Perkembangan teknologi komputasi telah melaju dengan kecepatan yang
luar biasa selama dekade terakhir. Pada masa-masa awal, komputer
terbatas pada prosesor \textit{single-core}. Keterbatasan ini memaksa
para insinyur dan pemrogram untuk merancang perangkat lunak yang
dioptimalkan untuk eksekusi \textit{single-threaded}. Seiring waktu,
ketika peningkatan kinerja mulai melambat karena batasan fisik dan
termal, industri beralih ke arsitektur \textit{multi-core} dan
paralel. Transisi ini memperkenalkan tantangan baru dalam desain
perangkat lunak, menuntut pengembang untuk mengadopsi model
pemrograman konkuren dan paralel untuk memanfaatkan sepenuhnya
kapabilitas perangkat keras modern. Akibatnya, pemahaman dan
optimalisasi aplikasi \textit{multi-threaded} telah menjadi aspek
penting dalam riset dan pengembangan komputasi modern.

\textit{Caching} telah lama menjadi bagian integral dari sistem
komputer. Mekanisme ini memainkan peran krusial dalam meningkatkan
kinerja sistem dengan menyimpan data yang sering diakses di lokasi
penyimpanan yang lebih cepat. Selama bertahun-tahun, berbagai
strategi \textit{caching} telah dikembangkan untuk mengoptimalkan
efisiensi pengambilan data di berbagai lingkungan, mulai dari sistem
operasi dan server web hingga sistem terdistribusi dan infrastruktur
\textit{cloud}.

Arsitektur \textit{multi-core}, yang telah menjadi standar industri,
juga menghadirkan tantangan signifikan bagi teknik \textit{caching}
yang ada. Dalam lingkungan seperti ini, beberapa inti prosesor sering
kali mengakses dan memodifikasi data \textit{cache} yang sama secara
bersamaan, yang dapat menyebabkan kondisi balapan (\textit{race
conditions}) dan inkonsistensi data. Untuk menjaga kebenaran data,
sebagian besar implementasi \textit{cache} tradisional menekankan
penggunaan kunci (\textit{locks}) selama operasi penyisipan, promosi,
dan modifikasi. Namun, penggunaan \textit{lock} yang berlebihan dapat
menimbulkan persaingan (\textit{contention}) dan mengurangi
paralelisme, yang pada akhirnya membatasi kinerja sistem pada
prosesor \textit{multi-core} modern.

Berbagai kebijakan penggantian \textit{cache} (\textit{cache
replacement policies}) telah diusulkan untuk mencapai tujuan desain
yang berbeda. Kebijakan \textbf{Least Recently Used (LRU)} umum
digunakan karena kemampuannya untuk mencapai \textit{miss ratio} yang
rendah dengan mempertahankan data yang sering diakses. Namun, LRU
memerlukan pembaruan dan sinkronisasi yang sering untuk memelihara
informasi kebaruan data secara presisi, yang meningkatkan
\textit{overhead} dari \textit{locking}. Di sisi lain, kebijakan yang
lebih sederhana seperti \textbf{First-In First-Out (FIFO)} sering
kali lebih disukai karena skalabilitasnya dan biaya sinkronisasi yang
lebih rendah, karena hampir tidak memerlukan \textit{locking}.

Untuk mengatasi keterbatasan LRU dan FIFO, algoritma \textbf{CLOCK}
dikembangkan sebagai aproksimasi dari LRU yang tetap mempertahankan
skalabilitas tinggi. CLOCK menggunakan \textit{buffer} melingkar
(\textit{circular buffer}) dari entri \textit{cache}, di mana setiap
entri memiliki bit referensi yang menandakan akses terkini. Alih-alih
memelihara daftar yang terurut sepenuhnya seperti LRU, algoritma ini
menggerakkan "jarum jam" untuk menemukan entri yang akan diganti,
sambil membersihkan bit referensi di sepanjang jalan. Desain ini
secara signifikan mengurangi kebutuhan akan \textit{locking} yang
berlebihan dan pembaruan yang sering, sambil tetap mempertahankan
manfaat dari LRU. Hasilnya, CLOCK menawarkan keseimbangan praktis
antara mencapai \textit{miss ratio} yang rendah dan menjaga
skalabilitas serta kesederhanaan yang menjadi ciri khas FIFO.

Namun, terlepas dari keunggulannya, algoritma CLOCK masih mengalami
masalah promosi yang tidak perlu. Karena setiap akses akan mengatur
bit referensi tanpa memandang frekuensi atau kepentingan akses,
bahkan akses tunggal atau yang jarang terjadi dapat mencegah sebuah
entri untuk digusur. Akibatnya, \textit{cache} dapat mempertahankan
item yang memberikan sedikit manfaat sambil menggusur item lain
dengan potensi penggunaan kembali yang lebih tinggi. Hal ini
menyebabkan inefisiensi dalam pemanfaatan \textit{cache}.

Perkembangan terkini dalam \textit{machine learning} telah membuka
kemungkinan untuk menggunakannya sebagai komponen pengambilan
keputusan tambahan untuk mengurangi promosi yang tidak perlu dalam
sistem \textit{cache}. Dengan belajar dari pola akses dan
mengidentifikasi objek yang kemungkinan besar tidak akan digunakan
kembali, model \textit{machine learning} dapat membantu mencegah
\textit{cache} mempromosikan entri yang memberikan sedikit manfaat.
Pendekatan ini memungkinkan mekanisme \textit{caching} untuk membuat
keputusan yang lebih selektif dan terinformasi tentang objek mana
yang layak dipertahankan. Dengan demikian, \textit{machine learning}
dapat melengkapi algoritma tradisional seperti CLOCK dengan
meningkatkan efisiensi, mengurangi \textit{overhead} manajemen, dan
beradaptasi secara dinamis terhadap karakteristik beban kerja yang berubah.

\section{Rumusan Masalah}
\label{sec:rumusan_masalah}

Berdasarkan pembahasan pada Latar Belakang, masalah utama yang
dibahas dalam penelitian ini adalah bagaimana mengintegrasikan teknik
\textit{machine learning} ke dalam algoritma penggantian
\textit{cache} CLOCK untuk mengurangi promosi yang tidak perlu dan
meningkatkan efisiensi sistem secara keseluruhan. Secara spesifik,
studi ini bertujuan untuk mengeksplorasi bagaimana pengambilan
keputusan berbasis data dapat membantu algoritma CLOCK untuk lebih
mendekati perilaku penggantian yang optimal. Dengan demikian,
penelitian ini berupaya untuk meningkatkan akurasi dan skalabilitas
dari manajemen \textit{cache} berbasis CLOCK.

\section{Tujuan Penelitian}
\label{sec:tujuan_penelitian}

Tujuan utama dari penelitian ini adalah sebagai berikut:
\begin{enumerate}[nolistsep]
  \item Mengintegrasikan model \textit{machine learning} ke dalam
    algoritma penggantian \textit{cache} CLOCK untuk menyempurnakan
    proses pengambilan keputusannya.
  \item Mengevaluasi efisiensi dan efektivitas algoritma CLOCK
    berbasis \textit{machine learning} dalam mengurangi jumlah
    promosi dan meningkatkan kinerja \textit{cache} secara keseluruhan.
\end{enumerate}

\section{Batasan Masalah}
\label{sec:batasan_masalah}

Studi ini berfokus pada integrasi teknik \textit{machine learning} ke
dalam algoritma penggantian \textit{cache} CLOCK untuk meningkatkan
efisiensinya. Penelitian ini terbatas pada lingkungan simulasi
\textit{cache} berbasis perangkat lunak, bukan implementasi perangkat
keras. Studi ini mengevaluasi metrik kinerja seperti \textit{hit
ratio} dan tingkat promosi.

Ruang lingkup penelitian tidak mencakup pengembangan arsitektur
\textit{machine learning} baru atau perbandingan dengan sistem
\textit{caching} berbasis \textit{reinforcement learning} yang
canggih. Sebaliknya, penelitian ini menekankan analisis tentang
bagaimana model ringan yang ada dapat meningkatkan pengambilan
keputusan di CLOCK tanpa meningkatkan kompleksitas secara signifikan.
Penelitian ini hanya berfokus pada promosi dan miss ratio serta tidak
menekankan performa asli pada perangkat keras nyata..

\section{Sistematika Penulisan}
\label{sec:sistematika_penulisan}

Laporan tugas akhir ini dibagi menjadi lima bab sebagai berikut:
\begin{enumerate}[nolistsep]
  \item \textbf{BAB I Pendahuluan}

    Bab ini menyajikan latar belakang studi, masalah utama yang akan
    dibahas, tujuan penelitian, dan ruang lingkup studi. Bab ini
    memberikan gambaran umum tentang motivasi dan signifikansi topik penelitian.
    \vspace{2ex}

  \item \textbf{BAB II Tinjauan Pustaka}

    Bab ini membahas karya-karya sebelumnya dan studi terkait yang
    menjadi landasan penelitian ini. Bab ini menyoroti algoritma
    penggantian \textit{cache} yang ada, pengembangan algoritma
    CLOCK, dan aplikasi \textit{machine learning} sebelumnya dalam
    sistem \textit{caching}.
    \vspace{2ex}

  \item \textbf{BAB III Perancangan dan Implementasi Sistem}

    Bab ini menjelaskan desain dan implementasi sistem yang
    diusulkan. Bab ini menjelaskan arsitektur sistem secara
    keseluruhan, alur data, integrasi model \textit{machine
    learning}, dan proses adaptasi model ke algoritma penggantian
    \textit{cache} CLOCK.
    \vspace{2ex}

  \item \textbf{BAB IV Pengujian dan Analisis}

    Bab ini menyajikan prosedur pengujian, pengaturan eksperimental,
    dan metrik evaluasi yang digunakan untuk mengukur kinerja sistem.
    Bab ini juga memberikan analisis hasil, membandingkan pendekatan
    yang diusulkan dengan metode dasar dalam hal efisiensi dan
    pengurangan promosi.
    \vspace{2ex}

  \item \textbf{BAB V Penutup}

    Bab ini merangkum temuan dan kontribusi penelitian. Bab ini juga
    membahas kemungkinan perbaikan dan rekomendasi untuk pekerjaan di
    masa depan terkait manajemen \textit{cache} berbasis
    \textit{machine learning}.
\end{enumerate}
